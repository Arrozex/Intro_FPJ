import gradio as gr
from openai import OpenAI
import os

# ====== è¨­å®š Groq API ======
client = OpenAI(
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"
)

# ====== è™•ç†å‡½æ•¸ ======
def emotion_for_pics(mood, diary):
    system_prompt = "ä½ æ˜¯ä¸€å€‹æƒ…æ„Ÿç”Ÿæˆè©å»ºè­°æ©Ÿå™¨äººï¼Œæ ¹æ“šç”¨æˆ¶å¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆä¸€å€‹é©åˆä½œç‚ºåœ–åƒç”Ÿæˆçš„å»ºè­°è©ã€‚"
    user_prompt = f"""å¿ƒæƒ…ï¼š{mood}\næ—¥è¨˜ï¼š{diary}\nè«‹æ ¹æ“šå¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆé©åˆåšç‚ºä¸€å¼µåœ–ç‰‡ç”Ÿæˆçš„å»ºè­°è©ï¼Œå¦‚ï¼šA melancholic rainy cityscape at dusk. A lonely person stands by the window, looking out with a distant gaze. The color palette is gray and blue, soft lighting, with raindrops on the glass. The atmosphere feels quiet, introspective, and emotionally heavy, evoking sadness and solitude.
ã€‚ä¸éœ€è¦è§£é‡‹æˆ–è©•è«–ï¼Œåªéœ€çµ¦å‡ºå»ºè­°è©ã€‚"""

    response = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.9
    )

    return response.choices[0].message.content

def emotion_for_music(mood, diary):
    system_prompt = "ä½ æ˜¯ä¸€å€‹æƒ…æ„Ÿç”Ÿæˆè©å»ºè­°æ©Ÿå™¨äººï¼Œæ ¹æ“šç”¨æˆ¶å¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆä¸€å€‹é©åˆä½œç‚ºéŸ³æ¨‚ç”Ÿæˆçš„å»ºè­°è©ã€‚"
    user_prompt = f"""å¿ƒæƒ…ï¼š{mood}\næ—¥è¨˜ï¼š{diary}\nè«‹æ ¹æ“šå¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆé©åˆå…±åŒç”Ÿæˆä¸€é¦–æ­Œçš„å»ºè­°è©ï¼Œå¦‚ï¼šA slow, emotional sad song with a melancholy piano as the main instrument, accompanied by soft strings in the background. The mood should be reflective and sorrowful, evoking feelings of heartbreak, loneliness, or nostalgia. Tempo should be slow and expressive, like a rainy afternoon where everything feels still and quiet.
ï¼Œä¸éœ€è¦è§£é‡‹æˆ–è©•è«–ï¼Œåªéœ€çµ¦å‡ºå»ºè­°è©ã€‚"""

    response = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.9
    )

    return response.choices[0].message.content

# ====== Gradio UI ======
with gr.Blocks() as demo:
    gr.Markdown("## ğŸµ å¿ƒæƒ…æ—¥è¨˜ç”Ÿæˆå™¨")

    mood = gr.Radio(["å¿«æ¨‚", "æ‚²å‚·", "ç„¦æ…®", "å¹³éœ", "æ†¤æ€’"], label="ä½ ä»Šå¤©çš„å¿ƒæƒ…æ˜¯ï¼Ÿ")
    diary = gr.Textbox(lines=5, placeholder="å¯«ä¸‹ä»Šå¤©çš„å¿ƒæƒ…...", label="æ—¥è¨˜å…§å®¹")

    submit = gr.Button("åˆ†æä¸¦ç”Ÿæˆ prompt")
    output_pic = gr.Textbox(label="åœ–ç‰‡æç¤º")
    output_music = gr.Textbox(label="éŸ³æ¨‚æç¤º")

    submit.click(fn=emotion_for_pics, inputs=[mood, diary], outputs=output_pic)
    submit.click(fn=emotion_for_music, inputs=[mood, diary], outputs=output_music)


demo.launch(share=True, debug=True)
