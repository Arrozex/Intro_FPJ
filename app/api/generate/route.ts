import gradio as gr
from openai import OpenAI
import os

# ====== è¨­å®š Groq API ======
client = OpenAI(
    api_key=os.getenv("GROQ_API_KEY"),
    base_url="https://api.groq.com/openai/v1"
)

# ========= ä¸»æµç¨‹ =========
def generate_main(mood, diary):
    try:
        status = "ğŸ¯ Step 1ï¼šåˆ†æå¿ƒæƒ…ä¸­..."
        prompt_pic = emotion_for_pics(mood, diary)
        print(status, prompt_pic)

        status = "ğŸ¯ Step 2ï¼šç”ŸæˆéŸ³æ¨‚æç¤º..."
        prompt_music = emotion_for_music(mood, diary)
        print(status, prompt_music)

        status = "ğŸ–¼ï¸ Step 3ï¼šç”Ÿæˆåœ–ç‰‡ä¸­..."
        print(status)
        image_url = generate_image(prompt_pic)

        status = "ğŸµ Step 4ï¼šç”ŸæˆéŸ³æ¨‚ä¸­..."
        print(status)
        # audio_url = generate_music_local(prompt_music)

        status = "âœ… å®Œæˆï¼"
        return prompt_pic, image_url, prompt_music, status

    except Exception as e:
        return "", None, "", None, f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"

# ========= åœ–åƒç”Ÿæˆæç¤ºè© =========
def emotion_for_pics(mood, diary):
    system_prompt = "ä½ æ˜¯ä¸€å€‹æƒ…æ„Ÿç”Ÿæˆè©å»ºè­°æ©Ÿå™¨äººï¼Œæ ¹æ“šç”¨æˆ¶å¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆä¸€å€‹é©åˆä½œç‚ºåœ–åƒç”Ÿæˆçš„å»ºè­°è©ã€‚"
    user_prompt = f"""å¿ƒæƒ…ï¼š{mood}\næ—¥è¨˜ï¼š{diary}\nè«‹æ ¹æ“šå¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆé©åˆåšç‚ºä¸€å¼µåœ–ç‰‡ç”Ÿæˆçš„å»ºè­°è©ï¼Œå¦‚ï¼šA melancholic rainy cityscape at dusk. ..."""

    response = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.9
    )

    return response.choices[0].message.content.strip()

# ========= éŸ³æ¨‚ç”Ÿæˆæç¤ºè© =========
def emotion_for_music(mood, diary):
    system_prompt = "ä½ æ˜¯ä¸€å€‹æƒ…æ„Ÿç”Ÿæˆè©å»ºè­°æ©Ÿå™¨äººï¼Œæ ¹æ“šç”¨æˆ¶å¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆä¸€å€‹é©åˆä½œç‚ºéŸ³æ¨‚ç”Ÿæˆçš„å»ºè­°è©ã€‚"
    user_prompt = f"""å¿ƒæƒ…ï¼š{mood}\næ—¥è¨˜ï¼š{diary}\nè«‹æ ¹æ“šå¿ƒæƒ…èˆ‡æ—¥è¨˜ï¼Œç”Ÿæˆé©åˆå…±åŒç”Ÿæˆä¸€é¦–æ­Œçš„å»ºè­°è©ï¼Œå¦‚ï¼šA slow, emotional sad song with..."""

    response = client.chat.completions.create(
        model="llama3-70b-8192",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.9
    )

    return response.choices[0].message.content.strip()

# ========= åœ–ç‰‡ç”Ÿæˆ =========
def generate_image(prompt):
    API_URL = "https://router.huggingface.co/hf-inference/models/stabilityai/stable-diffusion-3.5-large"
    headers = {"Authorization": f"Bearer {HUGGING_FACE_API}"}

    response = requests.post(API_URL, headers=headers, json={"inputs": prompt})
    if response.status_code == 200:
        with open("output.png", "wb") as f:
            f.write(response.content)
        return "output.png"
    else:
        print("åœ–ç‰‡ç”ŸæˆéŒ¯èª¤:", response.status_code, response.text)
        return "åœ–ç‰‡ç”Ÿæˆå¤±æ•—"

# ========= éŸ³æ¨‚ç”Ÿæˆ =========
def generate_music(prompt):
    headers = {
        "Authorization":  f"Bearer {HUGGING_FACE_API}",
        "Content-Type": "application/json"
    }

    response = requests.post(
        "https://api-inference.huggingface.co/models/facebook/musicgen-small",
        headers=headers,
        json={"inputs": prompt}
    )

    if response.status_code == 200:
        with open("generated_music.wav", "wb") as f:
            f.write(response.content)
        return "generated_music.wav"
    else:
        print("éŒ¯èª¤ï¼š", response.status_code, response.text)
        return None

# ========= Gradio UI =========
with gr.Blocks() as demo:
    gr.Markdown("## ğŸµ å¿ƒæƒ…æ—¥è¨˜ç”Ÿæˆå™¨")

    mood = gr.Radio(["å¿«æ¨‚", "æ‚²å‚·", "ç„¦æ…®", "å¹³éœ", "æ†¤æ€’"], label="ä½ ä»Šå¤©çš„å¿ƒæƒ…æ˜¯ï¼Ÿ")
    diary = gr.Textbox(lines=5, placeholder="å¯«ä¸‹ä»Šå¤©çš„å¿ƒæƒ…...", label="æ—¥è¨˜å…§å®¹")
    submit = gr.Button("åˆ†æä¸¦ç”Ÿæˆ prompt")

    output_pic_prompt = gr.Textbox(label="ğŸ¨ åœ–ç‰‡æè¿°è©")
    output_pic = gr.Image(label="ç”Ÿæˆåœ–ç‰‡")
    output_music_prompt = gr.Textbox(label="ğŸµ éŸ³æ¨‚æè¿°è©")
    # output_music = gr.Audio(label="ç”ŸæˆéŸ³æ¨‚", type="filepath")
    output_status = gr.Textbox(label="ğŸ“ ç”Ÿæˆç‹€æ…‹")  

    submit.click(
        fn=generate_main,
        inputs=[mood, diary],
        outputs=[output_pic_prompt, output_pic, output_music_prompt, output_status]
    )

demo.launch(share=True, debug=True)
